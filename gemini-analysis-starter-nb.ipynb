{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62fe0de",
   "metadata": {},
   "source": [
    "# gemini-analysis-starter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adf06762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PyPDF2 import PdfReader\n",
    "import numpy as np\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a8360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key = GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2b1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model = \"models/embedding-001\", \n",
    "    google_api_key = GOOGLE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc32c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    embedding_vector = embedding_model.embed_query(text)\n",
    "    return embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecd9cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_chunks(text):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
    "    chunks = splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5ee288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_embedding(text):\n",
    "    chunks = get_text_chunks(text) # always chunk before embedding -> embeddings rep more meaningful semantic units\n",
    "    embeddings = [get_embedding(chunk) for chunk in chunks]\n",
    "    average_embedding = np.mean(embeddings, axis=0)\n",
    "    return average_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ce055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"all_jobs.json\"\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    jobs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e232f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "resume_path = \"resume.pdf\"\n",
    "pdf_reader = PdfReader(resume_path)\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bfe25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_embedding = get_average_embedding(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8304d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_embeddings_all = []\n",
    "job_embeddings_relevant = []\n",
    "for job_title, job in jobs.items():\n",
    "    \n",
    "    all_values = \" \".join(f\"{key}: {value}\" for key, value in job.items())\n",
    "    relevant_values = \" \".join(f\"{key}: {value}\" for key, value in job.items() if key in ['title','position_description', 'qualifications'])\n",
    "    \n",
    "    all_values_embedding = get_average_embedding(all_values)\n",
    "    relevant_values_embedding = get_average_embedding(relevant_values)\n",
    "    \n",
    "    job_embeddings_all.append({\"job\": job, \"embedding\": relevant_values_embedding})\n",
    "    job_embeddings_relevant.append({\"jobs\": job, \"embedding\": relevant_values_embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9aa1b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(embeddings):\n",
    "    dimension = len(embeddings[0]['embedding'])\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    embeddings_array = np.array([emb['embedding'] for emb in embeddings], dtype=np.float32)\n",
    "    # populate index\n",
    "    index.add(embeddings_array)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "02d639ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = build_faiss_index(job_embeddings_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7e9001c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_faiss_index(index, query_embedding, k=15):\n",
    "    query_embedding_np = np.array([query_embedding], dtype=np.float32).reshape(1, -1)\n",
    "    distances, indices = index.search(query_embedding_np, k)\n",
    "    return distances, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2a4651f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = search_faiss_index(index, resume_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5b4ed9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(distances, indices, job_embeddings):\n",
    "    ranked_jobs = []\n",
    "    for distance, index in zip(distances[0], indices[0]):\n",
    "        ranked_jobs.append({\n",
    "           \"job\": job_embeddings[index][\"job\"],\n",
    "        })\n",
    "        \n",
    "    return ranked_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c89c519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_jobs = process_results(distances, indices, job_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ec94c333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_gemini_prompt(resume_text, ranked_job):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following job posting and the provided resume.\n",
    "    Based on the skills, experience, and requirements in the job descriptions, give me the top 5 jobs the candidate should apply for.\n",
    "    No need for explanations. \n",
    "\n",
    "    Resume:\n",
    "    {resume_text}\n",
    "\n",
    "    Job Posting:\n",
    "    {ranked_jobs}\n",
    "\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf2e4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = generate_gemini_prompt(text, ranked_jobs)\n",
    "response = model.generate_content(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e533a63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Electrical Engineering Co-op at Schweitzer Engineering Laboratories Inc\n",
      "2. Power Engineer Co-op in Research and Development at Schweitzer Engineering Laboratories Inc\n",
      "3. Electrical Engineering Co-op at Exelon\n",
      "4. Power Engineering (Electrical or Mechanical) Co-Op at ExecuPOWER, LLC\n",
      "5. Power Engineer Co-op at Schweiter Engineering Laboratories Inc\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
